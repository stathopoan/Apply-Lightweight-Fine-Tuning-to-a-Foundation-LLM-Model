{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db20a7a-48da-44cb-ad0c-b185050ac9c8",
   "metadata": {},
   "source": [
    "# Apply Lightweight Fine-Tuning to a Foundation Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce622fe-4026-4bb4-9074-0260f6792d2c",
   "metadata": {},
   "source": [
    "## In this project, we will bring together all of the essential components of a PyTorch + Hugging Face training and inference process. Specifically, we will:\n",
    "\n",
    "-  Load a pre-trained model and evaluate its performance\n",
    "-  Perform parameter-efficient fine tuning using the pre-trained model\n",
    "-  Perform inference using the fine-tuned model and compare its performance to the original model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bd768-b2ab-4366-abb6-a536712abded",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset selected is the dair-ai/emotion from huggingface. Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. More details [here](https://huggingface.co/datasets/dair-ai/emotion)odel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffe030b-c7bf-4d77-8c92-48364781cf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 12800\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 3200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dair-ai/emotion dataset.\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "#  \n",
    "dataset = load_dataset(\"dair-ai/emotion\",split=\"train\", trust_remote_code=True).train_test_split(\n",
    "    test_size=0.2, shuffle=True, seed=23\n",
    ")\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "# View the dataset characteristics\n",
    "print(dataset[\"train\"])\n",
    "print(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e50f475a-ee81-416e-9c4d-1304aba39489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i am feeling hopeful excited and very much being made new',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first example\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652903b-16c8-4f1c-b322-4a87731905d2",
   "metadata": {},
   "source": [
    "## Pre-process Dataset\n",
    "\n",
    "### Convert all text into tokens for our model. Here the tokenizer is the one suitable for the model selected. In this case: GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d807a31-c953-4305-b04f-0d32ee74f5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 12800\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" \n",
    "\n",
    "tokenized_dataset = {}\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = dataset[split].map(\n",
    "        lambda x: tokenizer(x[\"text\"], truncation=True, ), batched=True\n",
    "    )\n",
    "\n",
    "# Inspect the available columsn in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b031539e-b327-4ed6-a510-b433079edec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i am feeling hopeful excited and very much being made new',\n",
       " 'label': 1,\n",
       " 'input_ids': [72, 716, 4203, 17836, 6568, 290, 845, 881, 852, 925, 649],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31aead-26fa-4d91-ab36-10554f25385a",
   "metadata": {},
   "source": [
    "## Load and set up the foundation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81700455-d0d0-4435-a117-0d5c4d3e7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=6,\n",
    "    id2label={0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"},  # For converting predictions to strings\n",
    "    label2id={\"sadness\": 0, \"joy\": 1, \"love\": 2, \"anger\": 3, \"fear\": 4, \"surprise\": 5}\n",
    ")\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59f482d7-d2e2-4164-ae5f-ab7a88926cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=6, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8e7ca54-6ff9-4d49-904b-ca15f5bc6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "#def compute_metrics(eval_pred):\n",
    "#    predictions, labels = eval_pred\n",
    "#    predictions = np.argmax(predictions, axis=1)\n",
    "#    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "   # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(labels, preds, average='weighted')\n",
    "    recall = recall_score(labels, preds, average='weighted')\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ee867ab-925f-4ec2-bb01-d4bf73c19aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model using the Trainer library\n",
    "from transformers import DataCollatorWithPadding, DataCollator, Trainer, TrainingArguments\n",
    "\n",
    "foundation_model_trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6723e-ed42-4cce-8490-51534bc3f61f",
   "metadata": {},
   "source": [
    "## Evaluate foundation GPT2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73249be5-2f1a-45af-9dae-b52eb6d3cbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.2808918952941895,\n",
       " 'eval_accuracy': 0.306875,\n",
       " 'eval_precision': 0.21980305483006937,\n",
       " 'eval_recall': 0.306875,\n",
       " 'eval_f1': 0.1698034250640395,\n",
       " 'eval_runtime': 19.607,\n",
       " 'eval_samples_per_second': 163.207,\n",
       " 'eval_steps_per_second': 20.401}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foundation_model_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b8b36-17f7-4d53-8014-97c2b259be01",
   "metadata": {},
   "source": [
    "## Fine tune GPT2 model using PEFT - LoRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5a483bd-c8af-40b8-a8ac-2a5058922e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 299,520 || all params: 124,743,936 || trainable%: 0.24010786384037136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\peft\\tuners\\lora\\layer.py:711: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig\n",
    "config = LoraConfig(task_type=\"SEQ_CLS\", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)\n",
    "\n",
    "from peft import get_peft_model\n",
    "lora_model = get_peft_model(model, config)\n",
    "\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feeaa7c-cc83-46c3-8b45-be42a98afa26",
   "metadata": {},
   "source": [
    "#### We see that with PEFT we will train only 0.24% of the paratmeters in the model drastically recuding training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ae05fdd-8709-4e9b-b81a-c0687ef4e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./lora\",\n",
    "        # Set the learning rate\n",
    "        learning_rate = 2e-5,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        num_train_epochs=10,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True\n",
    "    ),\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f3185e2-9e03-4f3f-9018-dc8bdbaca275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 1:58:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.670760</td>\n",
       "      <td>0.334688</td>\n",
       "      <td>0.256958</td>\n",
       "      <td>0.334688</td>\n",
       "      <td>0.275154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.675200</td>\n",
       "      <td>1.541964</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.279814</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.322240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.573100</td>\n",
       "      <td>1.426909</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>0.347970</td>\n",
       "      <td>0.499688</td>\n",
       "      <td>0.391169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.428600</td>\n",
       "      <td>1.197828</td>\n",
       "      <td>0.570625</td>\n",
       "      <td>0.552126</td>\n",
       "      <td>0.570625</td>\n",
       "      <td>0.467414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.179900</td>\n",
       "      <td>1.031275</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.613510</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.535246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.179900</td>\n",
       "      <td>0.933653</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.661906</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.612027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.039100</td>\n",
       "      <td>0.863824</td>\n",
       "      <td>0.696562</td>\n",
       "      <td>0.679079</td>\n",
       "      <td>0.696562</td>\n",
       "      <td>0.647004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.951900</td>\n",
       "      <td>0.823895</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.676838</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.658148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.909800</td>\n",
       "      <td>0.800431</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.678923</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.669753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.793518</td>\n",
       "      <td>0.713125</td>\n",
       "      <td>0.681736</td>\n",
       "      <td>0.713125</td>\n",
       "      <td>0.673468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "lora_model.save_pretrained(\"lora_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb94591-c302-44d7-8721-9841e9e4d4e6",
   "metadata": {},
   "source": [
    "## Load the PEFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d48a256d-a5e1-46d6-809c-8042d06062a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification, PeftModel, PeftConfig\n",
    "\n",
    "peft_model_id = \"lora_model\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "inference_model = AutoPeftModelForSequenceClassification.from_pretrained(peft_model_id,pad_token_id=tokenizer.eos_token_id,id2label={0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"},  # For converting predictions to strings\n",
    "    label2id={\"sadness\": 0, \"joy\": 1, \"love\": 2, \"anger\": 3, \"fear\": 4, \"surprise\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "215531ea-aa47-44b5-88ec-b578d05d28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_lora_model_trainer = Trainer(\n",
    "    model=inference_model,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08bd19ec-7b97-442e-96be-6ae007f72e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\astathopoulos\\Udacity\\Apply-Lightweight-Fine-Tuning-to-a-Foundation-LLM-Model\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.79351806640625,\n",
       " 'eval_accuracy': 0.713125,\n",
       " 'eval_precision': 0.6817358319177603,\n",
       " 'eval_recall': 0.713125,\n",
       " 'eval_f1': 0.6734675567185461,\n",
       " 'eval_runtime': 32.1116,\n",
       " 'eval_samples_per_second': 99.653,\n",
       " 'eval_steps_per_second': 12.457}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_lora_model_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c742c84-c416-4cfe-9e66-ae2fd02546e1",
   "metadata": {},
   "source": [
    "#### Compare results between PGT2 and fine tuned GPT2:\n",
    "\n",
    "| Metric    | GPT2 | GPT2 PEFT |\r\n",
    "|-----------|------|-----------|\r\n",
    "| loss      | 4.28 | 0.79      |\r\n",
    "| accuracy  | 0.31 | 0.71      |\r\n",
    "| precision | 0.22 | 0.68      |\r\n",
    "| recall    | 0.31 | 0.71      |\r\n",
    "| f1        | 0.17 | 0.67      |.67 \t|.67 \t| 3_  |42.99 |   ||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88fd2f-35eb-4ddc-b392-86662359e1fb",
   "metadata": {},
   "source": [
    "##### As we can see we trained the model and achieved much better results by training a fraction of the foundation model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def906a8-34ef-4f80-9a49-9a284122440b",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f54e0f9b-e7c0-46a8-9666-c32ed98b5038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label={0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"}\n",
    "\n",
    "import torch\n",
    "\n",
    "def classify_text(text):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    outputs = inference_model(input_ids=inputs[\"input_ids\"])\n",
    "    return id2label[outputs.logits.argmax(dim=-1).to(device).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33a49fcb-6e89-413d-b09e-36bd7120e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I feel so sad -> sadness\n"
     ]
    }
   ],
   "source": [
    "sample_text_to_classify = \"I feel so sad\"\n",
    "print (sample_text_to_classify + \" -> \" + classify_text(sample_text_to_classify))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a3aed66-f443-46d4-bfde-f2db0e2dc6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am so happy -> joy\n"
     ]
    }
   ],
   "source": [
    "sample_text_to_classify = \"I am so happy\"\n",
    "print (sample_text_to_classify + \" -> \" + classify_text(sample_text_to_classify))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e307f09-d145-4e89-82df-916849b96b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
